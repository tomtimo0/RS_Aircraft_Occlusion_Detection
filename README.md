# 《模式识别与机器学习》课程设计

[课程设计要求、项目详情、考核与报告规范（点击查看）](./project_spec.md)

## 六、项目任务分解与时间规划 (To-Do List)
<details><summary>项目任务分解与时间规划 (To-Do List) (点击展开/折叠)</summary>

**项目核心：** 遮挡条件下遥感图像中的飞机目标检测 (使用高斯光斑模拟遮挡, DOTA数据集, 倾斜目标框回归)

**团队规模：** 5人 (组长进行协调和进度管理)

---

### **项目任务分解与时间规划 (To-Do List)**

#### **第一阶段：课题调研与方案设计 (第7周 - 第10周)**

**第7-8周：需求分析与初步调研**

*   **任务1：深入理解项目需求 (全体成员)**
    *   [x] 仔细阅读课程设计任务书，明确目标、任务描述、数据说明和考核标准。(相关指南请参考：[Git、GitHub操作与团队协作指南](#七gitgithub操作与团队协作指南))
    *   [ ] 小组讨论，确保每位成员对项目有统一和清晰的理解。
*   **任务2：文献调研与技术选型 (分工合作)**
    *   [ ] **成员A&B**: 调研 DOTA 数据集特性，飞机目标的特点，现有遥感图像目标检测方法。
    *   [ ] **成员C&D**: 调研 Faster R-CNN 及其优化算法，特别是针对小目标和旋转目标的改进。
    *   [ ] **成员E**: 调研图像遮挡模拟方法（尤其是高斯光斑），以及遮挡对目标检测影响的研究。
    *   [ ] **全体成员**: 收集至少6篇高质量参考文献，重点关注项目提及的文献。
*   **任务3：数据准备与熟悉 (成员A&B)**
    *   [ ] 下载DOTA数据集。
    *   [ ] 筛选出飞机目标子集，熟悉数据格式和标注。
*   **任务4：初步方案构思与讨论 (全体成员)**
    *   [ ] 讨论如何构建高斯光斑遮挡场景。
    *   [ ] 讨论如何设计遮挡程度的衡量指标。
    *   [ ] 初步确定核心检测算法选型。
    *   [ ] 讨论倾斜目标框的回归方法。
*   **任务5：制定详细工作计划与分工 (组长协调，全体确认)**
    *   [ ] 明确每个阶段的交付物。
    *   [ ] 细化每个成员的具体职责。

**第9-10周：方案设计与报告撰写**

*   **任务6：详细算法设计 (分工合作)**
    *   [ ] **成员C**: 设计高斯光斑生成算法，用于模拟不同程度的遮挡。
    *   [ ] **成员A**: 设计遮挡程度的量化指标。
    *   [ ] **成员D&E**: 详细设计基于所选框架（如Faster R-CNN）的飞机目标检测算法，包括网络结构、损失函数、倾斜框回归策略。
    *   [ ] **成员B**: 设计实验方案，如何分析遮挡程度、目标尺度对检测结果的影响。
*   **任务7：系统架构设计 (全体成员)**
    *   [ ] 绘制系统总体流程图。
    *   [ ] 确定各模块接口。
*   **任务8：撰写设计方案报告初稿 (分工撰写，组长汇总)**
    *   [ ] 章节1: 课题概述 (研究现状、意义) - **成员A**
    *   [ ] 章节2: 算法分析 (需求分析、研究方案、算法选择与分析) - **成员B&C**
    *   [ ] 章节3: 试验系统设计 (总体结构、模块功能) - **成员D&E**
    *   [ ] 全体成员：审核并完善初稿。

#### **第二阶段：方案评审与算法实现 (第11周 - 第13周)**

**第11周：方案评审与修改**

*   **任务9：提交设计方案报告 (组长)**
    *   [ ] 按时提交给指导老师。
*   **任务10：根据指导老师意见修改方案 (全体成员)**
    *   [ ] 认真记录反馈意见。
    *   [ ] 针对性修改和完善设计方案。

**第12-13周：算法设计与实现**

*   **任务11：开发环境搭建 (成员D或E，其他成员配合)**
    *   [ ] 配置深度学习框架 (PyTorch/TensorFlow)。
    *   [ ] 安装必要的库 (OpenCV, NumPy, etc.)。
    *   [ ] 建立代码仓库 (如Git)。
*   **任务12：核心模块编码实现 (分工合作)**
    *   [ ] **数据预处理模块 (成员A)**
        *   [ ] DOTA飞机数据加载与解析。
        *   [ ] 图像预处理 (裁剪、缩放、归一化等)。
    *   [ ] **高斯遮挡生成模块 (成员C)**
        *   [ ] 实现高斯光斑生成函数。
        *   [ ] 实现将光斑应用到图像指定区域的函数。
    *   [ ] **飞机目标检测模型 (成员D&E)**
        *   [ ] 基于选定框架搭建网络模型。
        *   [ ] 实现倾斜目标框的预测和回归。
        *   [ ] 实现模型训练代码。
    *   [ ] **遮挡程度计算模块 (成员B)**
        *   [ ] 实现设计的遮挡程度量化指标。
*   **任务13：单元测试 (各模块负责人)**
    *   [ ] 对各自实现的模块进行充分的单元测试，确保功能正确。

#### **第三阶段：软件实现与测试 (第14周 - 第15周)**

**第14-15周：软件实现与算法测试**

*   **任务14：系统集成与联调 (全体成员)**
    *   [ ] 将各模块集成为一个完整的检测系统。
    *   [ ] 解决集成过程中出现的接口和逻辑问题。
*   **任务15：构建遮挡测试数据集 (成员A&C)**
    *   [ ] 利用高斯遮挡模块，在原始飞机数据上生成不同遮挡程度、不同目标尺度的测试样本。
    *   [ ] 确保测试集的多样性和代表性。
*   **任务16：模型训练与调优 (成员D&E，其他成员协助分析)**
    *   [ ] 在无遮挡原始数据集上预训练模型。
    *   [ ] （可选）在混合了遮挡数据的数据集上进行训练或微调。
    *   [ ] 调整超参数，优化模型性能。
*   **任务17：综合实验与结果分析 (全体成员，各有侧重)**
    *   [ ] **成员B&C**: 在构建的遮挡测试集上进行实验，记录检测结果。
    *   [ ] **成员A**: 分析遮挡程度对检测准确率、召回率、倾斜框精度等指标的影响。
    *   [ ] **成员D&E**: 分析目标尺度对检测结果的影响。
    *   [ ] **全体成员**: 对比不同算法或参数设置下的实验结果（如果时间允许）。
    *   [ ] 记录实验过程中的问题、解决方法和经验教训。
*   **任务18：代码整理与注释 (全体成员)**
    *   [ ] 确保代码规范，注释清晰，注释比例不低于1:1。

#### **第四阶段：报告撰写与答辩准备 (第16周 - 第17周)**

**第16周：撰写课程设计报告**

*   **任务19：完成课程设计报告终稿 (分工合作，组长统稿)**
    *   [ ] **封面、摘要、目录 (组长)**
    *   [ ] **第一章 课题概述 (成员A)** - 更新研究现状，明确项目意义。
    *   [ ] **第二章 算法分析 (成员B&C)** - 完善算法选择理由，详细描述设计的遮挡和检测算法。
    *   [ ] **第三章 试验系统设计 (成员D&E)** - 详细描述系统架构、程序流程图、各模块功能和代码设计思路。
    *   [ ] **第四章 软件实施与实验运行 (全体成员)** - 详细记录软件实现过程、数据库测试、详尽的实验结果与深入分析 (图表结合)。
    *   [ ] **第五章 结束语 (组长，全体讨论)** - 总结研究结论，课程设计体会，明确每人工作划分和贡献。
    *   [ ] **附录 (各模块开发者)** - 附上主要模块的核心代码及注释。
    *   [ ] **参考文献 (全体成员)** - 整理并规范参考文献格式。
    *   [ ] **全体成员**: 交叉审阅报告，确保文字通顺、数据准确、图表清晰、格式规范。

**第17周：考核答辩**

*   **任务20：准备答辩PPT (分工合作，组长整合)**
    *   [ ] 内容应包括：项目背景、研究目标、方案设计、算法实现、实验结果与分析、结论与展望、个人贡献。
    *   [ ] PPT制作美观大方，逻辑清晰。
*   **任务21：准备成果演示 (负责编码和测试的成员)**
    *   [ ] 准备好可运行的检测系统和典型的测试样例。
    *   [ ] 确保演示流畅。
*   **任务22：答辩演练 (全体成员)**
    *   [ ] 模拟答辩场景，互相提问，熟悉答辩流程。
    *   [ ] 准备应对可能被问到的问题。
*   **任务23：参加答辩 (全体成员)**

---

**通用任务 (贯穿项目始终):**

*   [ ] 定期小组会议，同步进度，讨论问题。
*   [ ] 做好详细的会议记录和决策记录。
*   [ ] 积极与指导老师沟通，及时反馈问题并寻求指导。
*   [ ] 保证工作量饱满，积极参与，独立思考。
*   [ ] **切记独立完成，杜绝抄袭！**

</details>

[Git、GitHub操作与团队协作指南（点击查看）](./collab_guide.md)

## 本周计划

*   **仔细阅读课程设计任务书，明确目标、任务描述、数据说明和考核标准。** (详细内容已在README文档相关章节阐述，请参考：[课程设计要求、项目详情、考核与报告规范](#课程设计要求项目详情考核与报告规范-点击展开折叠)部分)
*   **团队成员各自阅读老师提供的三篇参考文献。**

<details>
<summary>文献阅读指引 (点击展开/折叠)</summary>

**通用阅读建议：**

*   **带着问题去读**：始终围绕你们项目的核心需求（飞机检测、遥感图像、遮挡、倾斜框、DOTA数据集、性能分析）来寻找答案。
*   **先看摘要、引言和结论**：快速了解论文的核心贡献和主要发现。
*   **重点关注方法部分**：详细理解模型架构、数据处理、训练策略和关键技术细节。
*   **实验部分看设置和结果**：了解他们是如何评估模型的，使用了哪些指标，在什么数据集上取得了什么效果。
*   **做笔记**：记录关键信息点、模型结构图、重要的公式、数据集细节、以及任何对你们项目有启发的地方。

---

**第一篇： "Aircraft Detection in Remote Sensing Images Based on Deep Convolutional Neural Network" (Li et al.)**

这篇论文直接针对遥感图像中的飞机检测，使用的是基于区域的卷积神经网络（具体提到了Faster R-CNN），与你们项目的基础方向一致。

**阅读时应注意：**

1.  **核心方法与模型架构 (Section II, III)**：
    *   **具体网络选择**：论文明确使用了 **Faster R-CNN**。理解其基本组成：RPN (Region Proposal Network) 和 Fast R-CNN 检测网络。
    *   **针对遥感图像飞机目标的改进**：
        *   **锚点框 (Anchor Boxes) 的调整 (Section III.A, Table I)**：论文提到"考虑到遥感图像中的飞机目标比自然图像中的目标小，我们将锚点框扩展到12个，并在相同的纵横比下增加了更小的64x64像素的锚点区域。" 这是**非常关键的一点**，因为DOTA数据集中也存在大量小目标飞机。你们需要仔细研究他们是如何调整锚点尺寸和比例的，这直接影响小目标的召回率。
        *   他们使用的是什么**骨干网络 (Backbone)**？（论文提及使用预训练的VGG-16，见Section IV.B）。
    *   **损失函数 (Section III.B)**：理解RPN和Fast R-CNN阶段的多任务损失函数，包括分类损失和回归损失。
    *   **坐标参数化 (Section III.B, Formula (2))**：了解他们是如何参数化边界框坐标进行回归的。

2.  **数据集与数据增强 (Section IV.A)**：
    *   他们构建了自己的数据集。虽然你们使用DOTA，但可以借鉴他们的数据增强方法（水平翻转、旋转90/180/270度），这对于提升模型鲁棒性很有帮助。
    *   他们如何组织标注文件 (XML) 和训练/测试列表 (TXT文件) 的。

3.  **训练策略 (Section III.B, IV.B)**：
    *   **样本分配**：RPN中正负样本是如何定义的（IoU阈值0.75为正，低于0.3为负）。
    *   **小批量采样 (Mini-batch sampling)**：如何平衡正负样本比例（1:1，总共256个锚点）。
    *   **迁移学习 (Transfer Learning)**：他们使用了在VGG-16上预训练的模型进行微调，这对于样本量相对不足时加速收敛和提升性能很重要。
    *   **训练参数 (Table II)**：如学习率 (base\_lr)、学习率策略 (lr\_policy)、权重衰减 (weight\_decay)、动量 (momentum) 等。

4.  **实验结果与分析 (Section IV.C)**：
    *   **性能指标**：他们使用了检测率 (Detection Rate) 和平均检测时间 (Average Detection time)。
    *   **对比分析**：与原始Faster R-CNN和FCN的比较，突出了RPN高质量提议区域的重要性以及小锚点框对小目标检测的优势。
    *   **对你们项目的启发**：这篇论文证明了调整锚点框对于小目标检测的有效性，你们在DOTA上实验时也应重点考虑这一点。

5.  **结论与未来工作 (Section V)**：
    *   注意他们提到的局限性，例如将所有飞机视为一类，未区分具体型号，以及对动态目标检测的展望。

**这篇论文对你们项目的核心价值在于：提供了一个在遥感图像上应用和改进Faster R-CNN进行飞机检测的具体案例，特别是针对小目标的锚点调整策略。**

---

**第二篇： "DOTA: A Large-scale Dataset for Object Detection in Aerial Images" (Xia et al.)**

这篇论文介绍了DOTA数据集，这是你们项目**必须使用的数据集**，因此至关重要。

**阅读时应注意：**

1.  **DOTA数据集的特性 (Section 1, 4)**：
    *   **规模与多样性**: 2806张航拍图，尺寸大 (约4000x4000像素)，包含15个类别，188,282个实例。
    *   **目标特性**: 目标尺度变化巨大、存在任意方向、形状各异、小目标密集。这些都是你们模型需要克服的挑战。
    *   **飞机类别**: DOTA包含 "plane" 类别。
    *   **实例密度 (Section 4.6, Figure 5c)**: 每张图像平均包含67.1个实例，远超PASCAL VOC和ImageNet。

2.  **标注方法 (Section 3, Figure 3)**：
    *   **关键点：任意四边形 (Oriented Bounding Box - OBB)**：DOTA使用 `{(xi, yi), i=1,2,3,4}` （顶点按顺时针排列）来标注有方向的目标。这是你们项目**必须输出的格式**。
    *   **第一个点的含义 (Section 3.3, Figure 3a)**：对于飞机等物体，"通常意味着物体的'头部'"。这对于你们任务描述中"给出目标中心（以原始无遮挡数据集中目标斜框中心为参考标注）"非常重要。你们需要思考如何利用这四个点或特别是第一个点来定义一个一致的"中心"。
    *   与水平框 (HBB) 相比，OBB能更紧凑地包围目标，尤其是在目标密集或有较大长宽比时。

3.  **数据处理与评估协议 (Section 5.2)**：
    *   **图像裁剪 (Patching)**：由于原始图像尺寸过大，论文中提到将图像裁剪成1024x1024的子块 (patches) 进行处理，步长 (stride) 为512。这对你们的实现有直接指导意义。
    *   **处理被切割的目标**：当目标被切割时，如果大部分（Ui >= 0.7）在一个子块中，则保留原标注；否则标记为困难样本。
    *   **结果合并与NMS**：在子块上得到检测结果后，需要合并回原始图像，并进行非极大值抑制 (NMS)。对于OBB实验，NMS阈值设为0.1。
    *   **评估指标**: 采用PASCAL VOC的mAP。

4.  **针对OBB的检测方法 (Section 5.4)**：
    *   论文中将Faster R-CNN修改为可以预测OBB。
    *   **核心回归目标**：RPN生成的RoI（矩形）表示为 `R = {(xi, yi)}`，真实OBB表示为 `G = {(gxi, gyi)}`。回归目标 `T = {(txi, tyi)}` 通过 `t_xi = (gx_i - x_i)/w` 和 `t_yi = (gy_i - y_i)/h` 计算。这里的 `(xi, yi)` 是RoI的顶点，`(w,h)`是RoI的宽高。这意味着模型需要直接回归OBB的四个顶点相对于RoI顶点和尺寸的偏移量。这是实现倾斜框检测的**核心数学公式和思路**。

5.  **实验分析 (Section 5.5, Figure 6)**：
    *   OBB在处理密集排列和有方向性目标时，相比HBB有明显优势。
    *   对于大长宽比的目标（如桥梁、港口），OBB回归仍然具有挑战性。

**这篇论文对你们项目的核心价值在于：详细介绍了你们将要使用的DOTA数据集的特性、标注方式（特别是OBB），以及如何在类似Faster R-CNN的框架下实现OBB的检测和评估。Section 5.4的OBB回归方法是你们需要重点理解和实现的部分。**

---

**第三篇： "Real-Time High-Resolution Background Matting" (Lin et al.)**

这篇论文的主题是**背景抠图 (Background Matting)**，即在已知背景的情况下，实时、高分辨率地将前景（通常是人）从视频中精确分割出来，并提取alpha蒙版。

**阅读时应注意：**

1.  **与你们项目的直接相关性**：
    *   **较低**。这篇论文的技术核心（双网络结构、基于背景参考的alpha抠图）与你们的飞机目标检测、遮挡模拟（高斯光斑）、倾斜框回归等任务没有直接的技术重叠。
    *   你们的任务是**检测**目标，而这篇论文是**分割/抠出**已知前景。
    *   你们的"遮挡"是由高斯光斑模拟的，而这篇论文的"背景"是预先拍摄的干净背景帧。

2.  **潜在的间接启发（可能比较牵强，需谨慎判断）：**
    *   **处理高分辨率图像的策略 (Section 4)**：论文提出用一个低分辨率的基础网络处理全图，然后用一个高分辨率的精炼网络在选定的"错误区域"进行优化。这种"粗到细"或者"全局到局部"的思想在处理大图像时是通用的。如果你们在处理DOTA的大图像时遇到严重的性能瓶颈，可以思考是否能借鉴类似的策略（但Faster R-CNN本身通过FPN等结构也有多尺度处理能力）。
    *   **误差预测图 (Error Prediction Map, Ec)**：基础网络会预测一个误差图，指导精炼网络在哪里进行处理。如果你们的遮挡分析需要特别关注某些区域，也许这个概念能带来一点点灵感。

3.  **数据集 (VideoMatte240K, PhotoMatte13K/85)**：这些是抠图数据集，与你们的目标检测数据集DOTA不同。

**这篇论文对你们项目的核心价值可能非常有限。除非老师有特别说明，否则你们应将主要精力放在前两篇论文上。** 如果时间充裕，可以了解一下其处理高分辨率视频的通用思路，但不要期望从中找到直接解决飞机检测或遮挡问题的方案。

---

**总结你们阅读论文时应重点关注并结合项目思考的问题：**

1.  **如何有效地在DOTA数据集上训练一个能够检测倾斜飞机框的Faster R-CNN类模型？** (综合Paper 1的锚点调整和Paper 2的OBB回归方法)
2.  **DOTA数据集的标注（四点OBB）如何用于定义"目标中心"？** (Paper 2，Section 3.3)
3.  **如何处理DOTA的大尺寸图像进行训练和测试？** (Paper 2的裁剪策略)
4.  **遮挡模拟（高斯光斑）如何整合到训练/测试流程中？** (论文本身不涉及，需要你们自己设计，但要知道是在什么模型基础上做)
5.  **如何设计实验来分析"遮挡程度"和"目标尺度"对检测结果的影响？** (论文提供检测模型和评估方法，你们需要基于此设计变量控制实验)
6.  **哪些训练参数、数据增强方法值得借鉴？** (Paper 1)

</details>