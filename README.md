# 《模式识别与机器学习》课程设计

[课程设计要求、项目详情、考核与报告规范（点击查看）](./project_spec.md)

## 项目任务分解与时间规划 (To-Do List)
<details><summary>项目任务分解与时间规划 (To-Do List) (点击展开/折叠)</summary>

**项目核心：** 遮挡条件下遥感图像中的飞机目标检测 (使用高斯光斑模拟遮挡, DOTA数据集, 倾斜目标框回归)

**团队规模：** 5人 (组长进行协调和进度管理)

---

### **项目任务分解与时间规划 (To-Do List)**

#### **第一阶段：加速调研、方案设计与初步搭建 (第12周)**

*   **任务1：深入理解项目需求与完成关键文献阅读 (全体成员)**
    *   [x] 仔细阅读课程设计任务书，明确目标、任务描述、数据说明和考核标准。(相关指南请参考：[Git、GitHub操作与团队协作指南](./collab_guide.md))
    *   [ ] 完成老师提供的三篇核心参考文献的阅读与初步分析。
    *   [ ] 小组讨论，统一对DOTA数据集特性、Faster R-CNN原理、高斯遮挡模拟方式、倾斜框检测思路的理解。
    *   [ ] （并行）调研其他相关近期文献，补充理解。
*   **任务2：数据准备、初步方案构思与高层设计 (全体成员，成员A&B主导数据，全体参与方案)**
    *   [ ] **数据方面 (成员A&B)**: 下载DOTA数据集，筛选飞机子集，熟悉数据格式与OBB标注。
    *   [ ] **方案构思 (全体)**:
        *   初步讨论高斯光斑生成方法与参数。
        *   初步讨论遮挡程度的衡量指标。
        *   初步确定核心检测算法选型（基于Faster R-CNN的调整思路）。
        *   讨论倾斜目标框的回归策略初步想法。
    *   [ ] **高层设计 (全体)**: 勾勒系统整体技术方案和主要模块划分。
*   **任务3：制定详细工作计划与开发环境搭建 (组长协调，全体确认；成员D或E主导环境)**
    *   [ ] 根据压缩后的时间制定详细到周的任务分解、责任人及交付物。
    *   [ ] **开发环境 (成员D或E)**: 搭建深度学习框架 (PyTorch/TensorFlow)，安装OpenCV, NumPy等必要库，确认Git仓库已建立并可用。

#### **第二阶段：详细设计与核心模块实现 (第13周)**

*   **任务4：详细算法与系统设计及文档化 (分工合作，全体评审)**
    *   [ ] **高斯遮挡模块设计 (成员C)**: 详细设计高斯光斑生成算法及参数化方案。
    *   [ ] **遮挡度量设计 (成员A)**: 详细设计遮挡程度的量化指标。
    *   [ ] **检测算法详细设计 (成员D&E)**:
        *   确定Faster R-CNN的具体网络结构（如骨干网络选择、FPN等）。
        *   设计针对DOTA飞机目标的锚点调整策略。
        *   详细设计倾斜框回归的数学表示与网络输出层。
        *   确定损失函数组成。
    *   [ ] **实验方案设计 (成员B)**: 设计如何评估遮挡程度、目标尺度对检测结果影响的实验流程。
    *   [ ] **系统架构确认 (全体)**: 绘制系统总体流程图，明确各模块接口。
    *   [ ] **文档化**: 撰写核心算法设计文档或详细的报告技术章节初稿。
*   **任务5：核心模块编码启动 (分工合作)**
    *   [ ] **数据预处理模块 (成员A)**: DOTA飞机数据加载、解析、图像预处理（裁剪、缩放、归一化，考虑DOTA的patching策略）。
    *   [ ] **高斯遮挡生成模块 (成员C)**: 编码实现高斯光斑生成函数，及将其应用于图像的函数。
    *   [ ] **飞机目标检测模型骨架 (成员D&E)**: 搭建基础网络模型结构，实现OBB预测的头部结构。
    *   [ ] **遮挡程度计算模块 (成员B)**: 编码实现设计的遮挡度量算法。

#### **第三阶段：模块完成、集成与测试数据准备 (第14周)**

*   **任务6：完成核心模块编码与单元测试 (各模块负责人)**
    *   [ ] 完成所有分配模块的编码工作。
    *   [ ] 对各自模块进行充分的单元测试，确保功能正确性与鲁棒性。
*   **任务7：系统集成与初步联调 (全体成员)**
    *   [ ] 将数据预处理、遮挡生成、检测模型等模块集成为一个初步可运行的流程。
    *   [ ] 解决集成过程中出现的接口和逻辑问题。
*   **任务8：构建遮挡测试数据集 (成员A&C)**
    *   [ ] 利用高斯遮挡模块，在原始DOTA飞机数据上生成具有不同遮挡程度、覆盖不同目标尺度的测试样本集。
    *   [ ] 确保测试集的多样性和代表性，并记录好每个样本的遮挡参数。

#### **第四阶段：模型训练、实验分析与代码完善 (第15周)**

*   **任务9：模型训练与调优 (成员D&E，其他成员协助分析)**
    *   [ ] 在无遮挡原始DOTA飞机数据子集上进行模型预训练或基线训练。
    *   [ ] 利用生成的遮挡数据集进行模型的训练或微调。
    *   [ ] 调整学习率、优化器、损失权重等超参数，优化模型在OBB检测上的性能 (mAP)。
*   **任务10：综合实验与结果分析 (全体成员，各有侧重)**
    *   [ ] **实验执行 (成员B&C)**: 在构建的遮挡测试集上运行训练好的模型，系统记录检测结果 (预测框、置信度等)。
    *   [ ] **遮挡影响分析 (成员A)**: 分析不同遮挡程度对检测准确率、召回率、OBB精度等指标的影响。
    *   [ ] **尺度影响分析 (成员D&E)**: 分析目标尺度对检测结果的影响。
    *   [ ] **结果汇总与可视化 (全体)**: 整理实验数据，制作图表进行清晰展示。
    *   [ ] 记录实验过程中的关键发现、问题和解决方法。
*   **任务11：代码整理与注释 (全体成员)**
    *   [ ] 确保最终代码结构清晰、规范，添加必要的JSDoc注释，保证注释比例。

#### **第五阶段：报告撰写 (第16周)**

*   **任务12：完成课程设计报告终稿 (分工合作，组长统稿)**
    *   [ ] **封面、摘要、目录 (组长)**
    *   [ ] **第一章 课题概述 (成员A)** - 更新研究现状，明确项目意义。
    *   [ ] **第二章 算法分析 (成员B&C)** - 完善算法选择理由，详细描述设计的遮挡模拟算法和倾斜框飞机检测算法。
    *   [ ] **第三章 试验系统设计 (成员D&E)** - 详细描述系统架构、程序流程图、各模块功能和核心代码设计思路。
    *   [ ] **第四章 软件实施与实验运行 (全体成员)** - 详细记录软件实现过程、数据库测试、详尽的实验结果与深入分析 (图表结合)。
    *   [ ] **第五章 结束语 (组长，全体讨论)** - 总结研究结论，课程设计体会，明确每人工作划分和贡献。
    *   [ ] **附录 (各模块开发者)** - 附上主要模块的核心代码及注释。
    *   [ ] **参考文献 (全体成员)** - 整理并规范参考文献格式。
    *   [ ] **全体成员**: 交叉审阅报告，确保文字通顺、数据准确、图表清晰、格式规范。

#### **第六阶段：答辩准备与考核 (第17周)**

*   **任务13：准备答辩PPT (分工合作，组长整合)**
    *   [ ] 内容应包括：项目背景、研究目标、方案设计、算法实现、实验结果与分析、结论与展望、个人贡献。
    *   [ ] PPT制作美观大方，逻辑清晰。
*   **任务14：准备成果演示 (负责编码和测试的成员)**
    *   [ ] 准备好可运行的检测系统和具有代表性的原始及遮挡测试样例。
    *   [ ] 确保演示流畅，能清晰展示系统功能和效果。
*   **任务15：答辩演练 (全体成员)**
    *   [ ] 模拟答辩场景，互相提问，熟悉答辩流程。
    *   [ ] 针对可能被问到的技术细节、实验结果、项目难点等进行准备。
*   **任务16：参加答辩 (全体成员)**

---

**通用任务 (贯穿项目始终):**

*   [ ] 定期小组会议（建议每周至少1-2次），同步进度，讨论问题，明确下一步计划。
*   [ ] 做好详细的会议记录和决策记录。
*   [ ] 积极与指导老师沟通，及时反馈项目进展和遇到的问题，并寻求指导。
*   [ ] 保证工作量饱满，积极参与，独立思考。

</details>

[Git、GitHub操作与团队协作指南（点击查看）](./collab_guide.md)

## 本周计划

*   **仔细阅读课程设计任务书，明确目标、任务描述、数据说明和考核标准。** (详细内容请参考：[课程设计要求、项目详情、考核与报告规范](./project_spec.md)部分)
*   **团队成员各自阅读老师提供的三篇参考文献。**
*   **理解并确认项目技术路线。** (详细规划请参考：[项目技术路线概要](./technical_path_summary.md))

<details>
<summary>文献阅读指引 (点击展开/折叠)</summary>

**通用阅读建议：**

*   **带着问题去读**：始终围绕项目的核心需求（飞机检测、遥感图像、遮挡、倾斜框、DOTA数据集、性能分析）来寻找答案。
*   **先看摘要、引言和结论**：快速了解论文的核心贡献和主要发现。
*   **重点关注方法部分**：详细理解模型架构、数据处理、训练策略和关键技术细节。
*   **实验部分看设置和结果**：了解他们是如何评估模型的，使用了哪些指标，在什么数据集上取得了什么效果。
*   **做笔记**：记录关键信息点、模型结构图、重要的公式、数据集细节、以及任何对项目有启发的地方。

---

**第一篇： "Aircraft Detection in Remote Sensing Images Based on Deep Convolutional Neural Network" (Li et al.)**

这篇论文直接针对遥感图像中的飞机检测，使用的是基于区域的卷积神经网络（具体提到了Faster R-CNN），与我们项目的基础方向一致。

**阅读时应注意：**

1.  **核心方法与模型架构 (Section II, III)**：
    *   **具体网络选择**：论文明确使用了 **Faster R-CNN**。理解其基本组成：RPN (Region Proposal Network) 和 Fast R-CNN 检测网络。
    *   **针对遥感图像飞机目标的改进**：
        *   **锚点框 (Anchor Boxes) 的调整 (Section III.A, Table I)**：论文提到"考虑到遥感图像中的飞机目标比自然图像中的目标小，我们将锚点框扩展到12个，并在相同的纵横比下增加了更小的64x64像素的锚点区域。" 这是**非常关键的一点**，因为DOTA数据集中也存在大量小目标飞机。我们需要仔细研究他们是如何调整锚点尺寸和比例的，这直接影响小目标的召回率。
        *   他们使用的是什么**骨干网络 (Backbone)**？（论文提及使用预训练的VGG-16，见Section IV.B）。
    *   **损失函数 (Section III.B)**：理解RPN和Fast R-CNN阶段的多任务损失函数，包括分类损失和回归损失。
    *   **坐标参数化 (Section III.B, Formula (2))**：了解他们是如何参数化边界框坐标进行回归的。

2.  **数据集与数据增强 (Section IV.A)**：
    *   他们构建了自己的数据集。虽然我们使用DOTA，但可以借鉴他们的数据增强方法（水平翻转、旋转90/180/270度），这对于提升模型鲁棒性很有帮助。
    *   他们如何组织标注文件 (XML) 和训练/测试列表 (TXT文件) 的。

3.  **训练策略 (Section III.B, IV.B)**：
    *   **样本分配**：RPN中正负样本是如何定义的（IoU阈值0.75为正，低于0.3为负）。
    *   **小批量采样 (Mini-batch sampling)**：如何平衡正负样本比例（1:1，总共256个锚点）。
    *   **迁移学习 (Transfer Learning)**：他们使用了在VGG-16上预训练的模型进行微调，这对于样本量相对不足时加速收敛和提升性能很重要。
    *   **训练参数 (Table II)**：如学习率 (base\_lr)、学习率策略 (lr\_policy)、权重衰减 (weight\_decay)、动量 (momentum) 等。

4.  **实验结果与分析 (Section IV.C)**：
    *   **性能指标**：他们使用了检测率 (Detection Rate) 和平均检测时间 (Average Detection time)。
    *   **对比分析**：与原始Faster R-CNN和FCN的比较，突出了RPN高质量提议区域的重要性以及小锚点框对小目标检测的优势。
    *   **对我们项目的启发**：这篇论文证明了调整锚点框对于小目标检测的有效性，我们在DOTA上实验时也应重点考虑这一点。

5.  **结论与未来工作 (Section V)**：
    *   注意他们提到的局限性，例如将所有飞机视为一类，未区分具体型号，以及对动态目标检测的展望。

**这篇论文对我们项目的核心价值在于：提供了一个在遥感图像上应用和改进Faster R-CNN进行飞机检测的具体案例，特别是针对小目标的锚点调整策略。**

---

**第二篇： "DOTA: A Large-scale Dataset for Object Detection in Aerial Images" (Xia et al.)**

这篇论文介绍了DOTA数据集，这是我们项目**必须使用的数据集**，因此至关重要。

**阅读时应注意：**

1.  **DOTA数据集的特性 (Section 1, 4)**：
    *   **规模与多样性**: 2806张航拍图，尺寸大 (约4000x4000像素)，包含15个类别，188,282个实例。
    *   **目标特性**: 目标尺度变化巨大、存在任意方向、形状各异、小目标密集。这些都是我们模型需要克服的挑战。
    *   **飞机类别**: DOTA包含 "plane" 类别。
    *   **实例密度 (Section 4.6, Figure 5c)**: 每张图像平均包含67.1个实例，远超PASCAL VOC和ImageNet。

2.  **标注方法 (Section 3, Figure 3)**：
    *   **关键点：任意四边形 (Oriented Bounding Box - OBB)**：DOTA使用 `{(xi, yi), i=1,2,3,4}` （顶点按顺时针排列）来标注有方向的目标。这是我们项目**必须输出的格式**。
    *   **第一个点的含义 (Section 3.3, Figure 3a)**：对于飞机等物体，"通常意味着物体的'头部'"。这对于我们任务描述中"给出目标中心（以原始无遮挡数据集中目标斜框中心为参考标注）"非常重要。我们需要思考如何利用这四个点或特别是第一个点来定义一个一致的"中心"。
    *   与水平框 (HBB) 相比，OBB能更紧凑地包围目标，尤其是在目标密集或有较大长宽比时。

3.  **数据处理与评估协议 (Section 5.2)**：
    *   **图像裁剪 (Patching)**：由于原始图像尺寸过大，论文中提到将图像裁剪成1024x1024的子块 (patches) 进行处理，步长 (stride) 为512。这对我们的实现有直接指导意义。
    *   **处理被切割的目标**：当目标被切割时，如果大部分（Ui >= 0.7）在一个子块中，则保留原标注；否则标记为困难样本。
    *   **结果合并与NMS**：在子块上得到检测结果后，需要合并回原始图像，并进行非极大值抑制 (NMS)。对于OBB实验，NMS阈值设为0.1。
    *   **评估指标**: 采用PASCAL VOC的mAP。

4.  **针对OBB的检测方法 (Section 5.4)**：
    *   论文中将Faster R-CNN修改为可以预测OBB。
    *   **核心回归目标**：RPN生成的RoI（矩形）表示为 `R = {(xi, yi)}`，真实OBB表示为 `G = {(gxi, gyi)}`。回归目标 `T = {(txi, tyi)}` 通过 `t_xi = (gx_i - x_i)/w` 和 `t_yi = (gy_i - y_i)/h` 计算。这里的 `(xi, yi)` 是RoI的顶点，`(w,h)`是RoI的宽高。这意味着模型需要直接回归OBB的四个顶点相对于RoI顶点和尺寸的偏移量。这是实现倾斜框检测的**核心数学公式和思路**。

5.  **实验分析 (Section 5.5, Figure 6)**：
    *   OBB在处理密集排列和有方向性目标时，相比HBB有明显优势。
    *   对于大长宽比的目标（如桥梁、港口），OBB回归仍然具有挑战性。

**这篇论文对我们项目的核心价值在于：详细介绍了我们将要使用的DOTA数据集的特性、标注方式（特别是OBB），以及如何在类似Faster R-CNN的框架下实现OBB的检测和评估。Section 5.4的OBB回归方法是我们需要重点理解和实现的部分。**

---

**第三篇： "You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery" (Van Etten)**

这篇论文提出了一种名为 YOLT (You Only Look Twice) 的方法，旨在解决卫星图像中多尺度、小目标快速检测的问题。它借鉴了YOLO的思想，但针对卫星图像的特性（大尺寸、小目标、旋转不变性等）进行了优化。虽然我们的项目指定使用Faster R-CNN作为基础，但YOLT中处理卫星图像的策略、面临的挑战以及解决方案，对我们有非常重要的参考价值。

**阅读时应注意：**

1.  **卫星图像目标检测的挑战 (Section 1, 2)**：
    *   **小目标问题 (Small spatial extent)**：卫星图像中的目标（如汽车、飞机）通常只占非常少的像素（文中提到约10-15像素）。这与Faster R-CNN论文中提到的锚点调整思路（Paper 1）以及DOTA数据集的小目标特性（Paper 2）是共通的挑战。
    *   **任意方向 (Complete rotation invariance)**：卫星图像中的目标（如船只、飞机）可以有任意朝向。虽然YOLT本身主要输出HBB，但其数据增强中提到了旋转，这与我们需要输出OBB的任务相关。
    *   **训练样本稀缺**：这也是常见问题。
    *   **超高分辨率图像 (Ultra high resolution)**：原始卫星图像尺寸巨大（如文中DigitalGlobe图像超过2.5亿像素，约16000x16000），远超标准检测网络的输入尺寸（几百x几百像素）。直接下采样会导致小目标信息丢失（见Figure 2左图）。

2.  **YOLT的核心方法与贡献 (Section 3)**：
    *   **解决大图问题：分块与合并 (Section 3.2, 3.3, Figure 4)**：
        *   **滑动窗口切割 (Sliding window cutouts)**：将大图切割成可管理的小块（如416x416），带有重叠（默认15%）。这与DOTA论文中处理大图的patching策略非常相似，是我们项目必须采用的方法。
        *   **结果合并与NMS**：在小块上检测后，需要将检测框的坐标转换回原始大图坐标，并对重叠区域的检测结果进行NMS。
    *   **针对小目标的网络架构改进 (Section 3.1, Table 1)**：
        *   **更细密的预测网格 (Denser final prediction grid)**：YOLT修改了YOLO的网络结构，使其下采样倍数减小（从32倍到16倍），得到更密集的预测网格（如416输入对应26x26网格，而标准YOLO是13x13）。这有助于区分密集小目标（见Figure 2右图的对比）。
        *   **Passthrough层**：类似于ResNet的恒等映射，将更早的、分辨率更高的特征图（52x52）连接到后续层，让检测器能获取更细粒度的特征。这对于小目标检测非常关键，Faster R-CNN中的FPN（特征金字塔网络）也有类似思想。
    *   **处理多尺度目标 (Section 6.2, 6.3)**：
        *   **双分类器/多尺度策略**：当目标尺度差异巨大时（如车辆 vs 机场），YOLT采用训练两个不同尺度的分类器：一个用于小目标（车辆、建筑），在较高分辨率的图像块上运行；另一个用于大目标（机场），在下采样后的图像块上运行。这对于我们项目中可能遇到的不同尺寸飞机，或未来扩展到其他类别时，是一个重要的启发。

3.  **数据增强 (Section 4)**：
    *   **旋转增强**：为了实现旋转不变性，对训练图像进行旋转。
    *   **HSV颜色空间随机缩放**：增强模型对不同传感器、光照、大气条件的鲁棒性。

4.  **实验与结果 (Section 6, 7)**：
    *   **数据集**：COWC (车辆), SpaceNet (建筑轮廓), 自标注飞机、船只、机场数据。
    *   **性能指标**：F1分数，车辆检测使用了较低的IoU阈值 (0.25)，建筑和机场使用0.5。
    *   **车辆检测性能 (Figure 7, 9)**：在COWC数据集上取得了较好的F1分数 (约0.9)。
    *   **分辨率性能研究 (Section 7, Figure 11, 13)**：系统研究了图像分辨率（GSD）对车辆检测性能的影响。结论是对于约5像素大小的目标仍能较好检测。这对于我们理解模型在不同条件下的能力上限有帮助。
        *   一个在高分辨率图像上训练的模型直接用于低分辨率测试时性能会快速下降（Figure 11）。
        *   为每个分辨率单独训练模型效果更好（Figure 13）。

5.  **对我们项目的启发与思考**：
    *   **处理DOTA大图的策略**：YOLT的分块、重叠、结果合并NMS的流程 (Section 3.2, 3.3) 与DOTA论文的建议一致，是我们项目实现中需要严格遵循的。
    *   **小目标检测增强**：YOLT的网络修改思路（更密集的网格、Passthrough层）虽然是针对YOLO的，但其核心思想（保留更多小目标信息、利用高分辨率特征）与Faster R-CNN结合FPN等改进方向是一致的。Paper 1中Faster R-CNN的锚点调整也是针对小目标的。
    *   **多尺度检测策略**：如果DOTA数据中的飞机目标尺度差异过大，或者我们希望模型能同时处理不同类型的目标，可以考虑YOLT提出的训练多个针对不同尺度的模型的思路。
    *   **旋转不变性**：虽然我们的目标是输出OBB，YOLT主要输出HBB，但其通过旋转数据增强来处理任意朝向的思路是值得借鉴的。DOTA数据集本身就需要处理任意方向的目标。
    *   **实验评估**：YOLT对不同类别使用不同IoU阈值，以及对分辨率影响的详细分析，为我们设计实验和评估模型提供了参考。

**这篇论文的核心价值在于：提供了一套完整的、针对卫星图像特性（大尺寸、小目标、多尺度）的快速检测流程。它在图像预处理（分块）、网络结构（针对小目标）、多尺度目标处理策略以及详尽的性能分析方面，都为我们的项目提供了宝贵的经验和思路，即便我们使用的是Faster R-CNN框架。**

---

**总结我们阅读论文时应重点关注并结合项目思考的问题：**

1.  **核心检测模型构建：** 如何基于Faster R-CNN，有效地在DOTA数据集上训练一个能够精确检测**倾斜飞机框 (OBB)** 的模型？
    *   *参考：Paper 1 (Li et al.) 中针对遥感小目标的Faster R-CNN锚点调整策略；Paper 2 (DOTA) 中的OBB标注方式及直接回归OBB四个顶点坐标的思路 (Section 5.4)；Paper 3 (YOLT) 中针对小目标和密集目标的网络设计思想（如更细密预测网格、passthrough层，启发我们思考FPN的有效利用或特征增强）。*
2.  **DOTA数据特性与处理：**
    *   如何精确理解和使用DOTA数据集的OBB标注（四个顶点，顺时针，首点含义）来定义"目标中心"并指导OBB回归？ (Paper 2, Section 3.3)
    *   如何高效处理DOTA数据集中的**大尺寸图像**（如4000x4000像素）进行训练和测试？
        *   *参考：Paper 2 (DOTA) 提出的图像裁剪 (patching) 策略；Paper 3 (YOLT) 中更详细的滑动窗口分块 (cutouts)、设定重叠区域 (overlap) 及后续结果合并与NMS的方法。*
3.  **关键技术点：**
    *   我们项目核心的**高斯光斑遮挡模拟**方法，应如何设计并整合到模型的训练和测试流程中？（此为项目创新点，三篇论文主要提供基础检测框架和思路）
    *   如何借鉴论文中的**数据增强**方法（如旋转、翻转、颜色扰动等）来提升模型的鲁棒性和泛化能力，特别是针对遥感图像的任意方向特性？ (Paper 1, Paper 3)
4.  **实验设计与评估：**
    *   如何设计系统的实验来分析**"遮挡程度"**和**"目标尺度"**对检测性能（如mAP、OBB的IoU、中心点偏移等）的影响？
        *   *参考：Paper 3 (YOLT) 中关于目标尺寸/分辨率对检测性能影响的详细定量分析方法 (Section 7)。*
    *   在模型评估时，如何根据目标特性（如小目标、倾斜框）合理选择或调整评估指标和IoU阈值？(Paper 3中对不同类别使用不同IoU的例子)
5.  **训练策略与参数：** 从三篇论文的实验中，我们可以借鉴哪些有效的训练参数（如学习率、优化器、batch size）、损失函数设计以及迁移学习等策略？ (Paper 1, Paper 3)
6.  **多尺度目标问题：** 考虑到DOTA数据集中飞机目标可能存在的较大尺度变化，是否需要以及如何借鉴Paper 3 (YOLT) 中的**多尺度检测策略**（例如，针对不同尺度范围训练特定模型，或在单一模型中强化多尺度特征融合能力，如FPN的应用和优化）？

</details>