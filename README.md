# 《模式识别与机器学习》课程设计

[课程设计要求、项目详情、考核与报告规范（点击查看）](./project_spec.md)

## 项目任务分解与时间规划 (To-Do List)
<details><summary>项目任务分解与时间规划 (To-Do List) (点击展开/折叠)</summary>

**项目核心：** 遮挡条件下遥感图像中的飞机目标检测 (使用高斯光斑模拟遮挡, DOTA数据集, 倾斜目标框回归)

**团队规模：** 5人 (组长进行协调和进度管理)

---

### **项目任务分解与时间规划 (To-Do List)**

#### **第一阶段：加速调研、方案设计与初步搭建 (第12周)**

*   **任务1：深入理解项目需求与完成关键文献阅读 (全体成员)**
    *   [x] 仔细阅读课程设计任务书，明确目标、任务描述、数据说明和考核标准。(相关指南请参考：[Git、GitHub操作与团队协作指南](./collab_guide.md))
    *   [ ] 完成老师提供的三篇核心参考文献的阅读与初步分析。
    *   [ ] 小组讨论，统一对DOTA数据集特性、Faster R-CNN原理、高斯遮挡模拟方式、倾斜框检测思路的理解。
    *   [ ] （并行）调研其他相关近期文献，补充理解。
*   **任务2：数据准备、初步方案构思与高层设计 (全体成员，成员A&B主导数据，全体参与方案)**
    *   [ ] **数据方面 (成员A&B)**: 下载DOTA数据集，筛选飞机子集，熟悉数据格式与OBB标注。
    *   [ ] **方案构思 (全体)**:
        *   初步讨论高斯光斑生成方法与参数。
        *   初步讨论遮挡程度的衡量指标。
        *   初步确定核心检测算法选型（基于Faster R-CNN的调整思路）。
        *   讨论倾斜目标框的回归策略初步想法。
    *   [ ] **高层设计 (全体)**: 勾勒系统整体技术方案和主要模块划分。
*   **任务3：制定详细工作计划与开发环境搭建 (组长协调，全体确认；成员D或E主导环境)**
    *   [ ] 根据压缩后的时间制定详细到周的任务分解、责任人及交付物。
    *   [ ] **开发环境 (成员D或E)**: 搭建深度学习框架 (PyTorch/TensorFlow)，安装OpenCV, NumPy等必要库，确认Git仓库已建立并可用。

#### **第二阶段：详细设计与核心模块实现 (第13周)**

*   **任务4：详细算法与系统设计及文档化 (分工合作，全体评审)**
    *   [ ] **高斯遮挡模块设计 (成员C)**: 详细设计高斯光斑生成算法及参数化方案。
    *   [ ] **遮挡度量设计 (成员A)**: 详细设计遮挡程度的量化指标。
    *   [ ] **检测算法详细设计 (成员D&E)**:
        *   确定Faster R-CNN的具体网络结构（如骨干网络选择、FPN等）。
        *   设计针对DOTA飞机目标的锚点调整策略。
        *   详细设计倾斜框回归的数学表示与网络输出层。
        *   确定损失函数组成。
    *   [ ] **实验方案设计 (成员B)**: 设计如何评估遮挡程度、目标尺度对检测结果影响的实验流程。
    *   [ ] **系统架构确认 (全体)**: 绘制系统总体流程图，明确各模块接口。
    *   [ ] **文档化**: 撰写核心算法设计文档或详细的报告技术章节初稿。
*   **任务5：核心模块编码启动 (分工合作)**
    *   [ ] **数据预处理模块 (成员A)**: DOTA飞机数据加载、解析、图像预处理（裁剪、缩放、归一化，考虑DOTA的patching策略）。
    *   [ ] **高斯遮挡生成模块 (成员C)**: 编码实现高斯光斑生成函数，及将其应用于图像的函数。
    *   [ ] **飞机目标检测模型骨架 (成员D&E)**: 搭建基础网络模型结构，实现OBB预测的头部结构。
    *   [ ] **遮挡程度计算模块 (成员B)**: 编码实现设计的遮挡度量算法。

#### **第三阶段：模块完成、集成与测试数据准备 (第14周)**

*   **任务6：完成核心模块编码与单元测试 (各模块负责人)**
    *   [ ] 完成所有分配模块的编码工作。
    *   [ ] 对各自模块进行充分的单元测试，确保功能正确性与鲁棒性。
*   **任务7：系统集成与初步联调 (全体成员)**
    *   [ ] 将数据预处理、遮挡生成、检测模型等模块集成为一个初步可运行的流程。
    *   [ ] 解决集成过程中出现的接口和逻辑问题。
*   **任务8：构建遮挡测试数据集 (成员A&C)**
    *   [ ] 利用高斯遮挡模块，在原始DOTA飞机数据上生成具有不同遮挡程度、覆盖不同目标尺度的测试样本集。
    *   [ ] 确保测试集的多样性和代表性，并记录好每个样本的遮挡参数。

#### **第四阶段：模型训练、实验分析与代码完善 (第15周)**

*   **任务9：模型训练与调优 (成员D&E，其他成员协助分析)**
    *   [ ] 在无遮挡原始DOTA飞机数据子集上进行模型预训练或基线训练。
    *   [ ] 利用生成的遮挡数据集进行模型的训练或微调。
    *   [ ] 调整学习率、优化器、损失权重等超参数，优化模型在OBB检测上的性能 (mAP)。
*   **任务10：综合实验与结果分析 (全体成员，各有侧重)**
    *   [ ] **实验执行 (成员B&C)**: 在构建的遮挡测试集上运行训练好的模型，系统记录检测结果 (预测框、置信度等)。
    *   [ ] **遮挡影响分析 (成员A)**: 分析不同遮挡程度对检测准确率、召回率、OBB精度等指标的影响。
    *   [ ] **尺度影响分析 (成员D&E)**: 分析目标尺度对检测结果的影响。
    *   [ ] **结果汇总与可视化 (全体)**: 整理实验数据，制作图表进行清晰展示。
    *   [ ] 记录实验过程中的关键发现、问题和解决方法。
*   **任务11：代码整理与注释 (全体成员)**
    *   [ ] 确保最终代码结构清晰、规范，添加必要的JSDoc注释，保证注释比例。

#### **第五阶段：报告撰写 (第16周)**

*   **任务12：完成课程设计报告终稿 (分工合作，组长统稿)**
    *   [ ] **封面、摘要、目录 (组长)**
    *   [ ] **第一章 课题概述 (成员A)** - 更新研究现状，明确项目意义。
    *   [ ] **第二章 算法分析 (成员B&C)** - 完善算法选择理由，详细描述设计的遮挡模拟算法和倾斜框飞机检测算法。
    *   [ ] **第三章 试验系统设计 (成员D&E)** - 详细描述系统架构、程序流程图、各模块功能和核心代码设计思路。
    *   [ ] **第四章 软件实施与实验运行 (全体成员)** - 详细记录软件实现过程、数据库测试、详尽的实验结果与深入分析 (图表结合)。
    *   [ ] **第五章 结束语 (组长，全体讨论)** - 总结研究结论，课程设计体会，明确每人工作划分和贡献。
    *   [ ] **附录 (各模块开发者)** - 附上主要模块的核心代码及注释。
    *   [ ] **参考文献 (全体成员)** - 整理并规范参考文献格式。
    *   [ ] **全体成员**: 交叉审阅报告，确保文字通顺、数据准确、图表清晰、格式规范。

#### **第六阶段：答辩准备与考核 (第17周)**

*   **任务13：准备答辩PPT (分工合作，组长整合)**
    *   [ ] 内容应包括：项目背景、研究目标、方案设计、算法实现、实验结果与分析、结论与展望、个人贡献。
    *   [ ] PPT制作美观大方，逻辑清晰。
*   **任务14：准备成果演示 (负责编码和测试的成员)**
    *   [ ] 准备好可运行的检测系统和具有代表性的原始及遮挡测试样例。
    *   [ ] 确保演示流畅，能清晰展示系统功能和效果。
*   **任务15：答辩演练 (全体成员)**
    *   [ ] 模拟答辩场景，互相提问，熟悉答辩流程。
    *   [ ] 针对可能被问到的技术细节、实验结果、项目难点等进行准备。
*   **任务16：参加答辩 (全体成员)**

---

**通用任务 (贯穿项目始终):**

*   [ ] 定期小组会议（建议每周至少1-2次），同步进度，讨论问题，明确下一步计划。
*   [ ] 做好详细的会议记录和决策记录。
*   [ ] 积极与指导老师沟通，及时反馈项目进展和遇到的问题，并寻求指导。
*   [ ] 保证工作量饱满，积极参与，独立思考。
*   [ ] **切记独立完成，杜绝抄袭！**

</details>

[Git、GitHub操作与团队协作指南（点击查看）](./collab_guide.md)

## 本周计划

*   **仔细阅读课程设计任务书，明确目标、任务描述、数据说明和考核标准。** (详细内容请参考：[课程设计要求、项目详情、考核与报告规范](./project_spec.md)部分)
*   **团队成员各自阅读老师提供的三篇参考文献。**

<details>
<summary>文献阅读指引 (点击展开/折叠)</summary>

**通用阅读建议：**

*   **带着问题去读**：始终围绕项目的核心需求（飞机检测、遥感图像、遮挡、倾斜框、DOTA数据集、性能分析）来寻找答案。
*   **先看摘要、引言和结论**：快速了解论文的核心贡献和主要发现。
*   **重点关注方法部分**：详细理解模型架构、数据处理、训练策略和关键技术细节。
*   **实验部分看设置和结果**：了解他们是如何评估模型的，使用了哪些指标，在什么数据集上取得了什么效果。
*   **做笔记**：记录关键信息点、模型结构图、重要的公式、数据集细节、以及任何对项目有启发的地方。

---

**第一篇： "Aircraft Detection in Remote Sensing Images Based on Deep Convolutional Neural Network" (Li et al.)**

这篇论文直接针对遥感图像中的飞机检测，使用的是基于区域的卷积神经网络（具体提到了Faster R-CNN），与我们项目的基础方向一致。

**阅读时应注意：**

1.  **核心方法与模型架构 (Section II, III)**：
    *   **具体网络选择**：论文明确使用了 **Faster R-CNN**。理解其基本组成：RPN (Region Proposal Network) 和 Fast R-CNN 检测网络。
    *   **针对遥感图像飞机目标的改进**：
        *   **锚点框 (Anchor Boxes) 的调整 (Section III.A, Table I)**：论文提到"考虑到遥感图像中的飞机目标比自然图像中的目标小，我们将锚点框扩展到12个，并在相同的纵横比下增加了更小的64x64像素的锚点区域。" 这是**非常关键的一点**，因为DOTA数据集中也存在大量小目标飞机。我们需要仔细研究他们是如何调整锚点尺寸和比例的，这直接影响小目标的召回率。
        *   他们使用的是什么**骨干网络 (Backbone)**？（论文提及使用预训练的VGG-16，见Section IV.B）。
    *   **损失函数 (Section III.B)**：理解RPN和Fast R-CNN阶段的多任务损失函数，包括分类损失和回归损失。
    *   **坐标参数化 (Section III.B, Formula (2))**：了解他们是如何参数化边界框坐标进行回归的。

2.  **数据集与数据增强 (Section IV.A)**：
    *   他们构建了自己的数据集。虽然我们使用DOTA，但可以借鉴他们的数据增强方法（水平翻转、旋转90/180/270度），这对于提升模型鲁棒性很有帮助。
    *   他们如何组织标注文件 (XML) 和训练/测试列表 (TXT文件) 的。

3.  **训练策略 (Section III.B, IV.B)**：
    *   **样本分配**：RPN中正负样本是如何定义的（IoU阈值0.75为正，低于0.3为负）。
    *   **小批量采样 (Mini-batch sampling)**：如何平衡正负样本比例（1:1，总共256个锚点）。
    *   **迁移学习 (Transfer Learning)**：他们使用了在VGG-16上预训练的模型进行微调，这对于样本量相对不足时加速收敛和提升性能很重要。
    *   **训练参数 (Table II)**：如学习率 (base\_lr)、学习率策略 (lr\_policy)、权重衰减 (weight\_decay)、动量 (momentum) 等。

4.  **实验结果与分析 (Section IV.C)**：
    *   **性能指标**：他们使用了检测率 (Detection Rate) 和平均检测时间 (Average Detection time)。
    *   **对比分析**：与原始Faster R-CNN和FCN的比较，突出了RPN高质量提议区域的重要性以及小锚点框对小目标检测的优势。
    *   **对我们项目的启发**：这篇论文证明了调整锚点框对于小目标检测的有效性，我们在DOTA上实验时也应重点考虑这一点。

5.  **结论与未来工作 (Section V)**：
    *   注意他们提到的局限性，例如将所有飞机视为一类，未区分具体型号，以及对动态目标检测的展望。

**这篇论文对我们项目的核心价值在于：提供了一个在遥感图像上应用和改进Faster R-CNN进行飞机检测的具体案例，特别是针对小目标的锚点调整策略。**

---

**第二篇： "DOTA: A Large-scale Dataset for Object Detection in Aerial Images" (Xia et al.)**

这篇论文介绍了DOTA数据集，这是我们项目**必须使用的数据集**，因此至关重要。

**阅读时应注意：**

1.  **DOTA数据集的特性 (Section 1, 4)**：
    *   **规模与多样性**: 2806张航拍图，尺寸大 (约4000x4000像素)，包含15个类别，188,282个实例。
    *   **目标特性**: 目标尺度变化巨大、存在任意方向、形状各异、小目标密集。这些都是我们模型需要克服的挑战。
    *   **飞机类别**: DOTA包含 "plane" 类别。
    *   **实例密度 (Section 4.6, Figure 5c)**: 每张图像平均包含67.1个实例，远超PASCAL VOC和ImageNet。

2.  **标注方法 (Section 3, Figure 3)**：
    *   **关键点：任意四边形 (Oriented Bounding Box - OBB)**：DOTA使用 `{(xi, yi), i=1,2,3,4}` （顶点按顺时针排列）来标注有方向的目标。这是我们项目**必须输出的格式**。
    *   **第一个点的含义 (Section 3.3, Figure 3a)**：对于飞机等物体，"通常意味着物体的'头部'"。这对于我们任务描述中"给出目标中心（以原始无遮挡数据集中目标斜框中心为参考标注）"非常重要。我们需要思考如何利用这四个点或特别是第一个点来定义一个一致的"中心"。
    *   与水平框 (HBB) 相比，OBB能更紧凑地包围目标，尤其是在目标密集或有较大长宽比时。

3.  **数据处理与评估协议 (Section 5.2)**：
    *   **图像裁剪 (Patching)**：由于原始图像尺寸过大，论文中提到将图像裁剪成1024x1024的子块 (patches) 进行处理，步长 (stride) 为512。这对我们的实现有直接指导意义。
    *   **处理被切割的目标**：当目标被切割时，如果大部分（Ui >= 0.7）在一个子块中，则保留原标注；否则标记为困难样本。
    *   **结果合并与NMS**：在子块上得到检测结果后，需要合并回原始图像，并进行非极大值抑制 (NMS)。对于OBB实验，NMS阈值设为0.1。
    *   **评估指标**: 采用PASCAL VOC的mAP。

4.  **针对OBB的检测方法 (Section 5.4)**：
    *   论文中将Faster R-CNN修改为可以预测OBB。
    *   **核心回归目标**：RPN生成的RoI（矩形）表示为 `R = {(xi, yi)}`，真实OBB表示为 `G = {(gxi, gyi)}`。回归目标 `T = {(txi, tyi)}` 通过 `t_xi = (gx_i - x_i)/w` 和 `t_yi = (gy_i - y_i)/h` 计算。这里的 `(xi, yi)` 是RoI的顶点，`(w,h)`是RoI的宽高。这意味着模型需要直接回归OBB的四个顶点相对于RoI顶点和尺寸的偏移量。这是实现倾斜框检测的**核心数学公式和思路**。

5.  **实验分析 (Section 5.5, Figure 6)**：
    *   OBB在处理密集排列和有方向性目标时，相比HBB有明显优势。
    *   对于大长宽比的目标（如桥梁、港口），OBB回归仍然具有挑战性。

**这篇论文对我们项目的核心价值在于：详细介绍了我们将要使用的DOTA数据集的特性、标注方式（特别是OBB），以及如何在类似Faster R-CNN的框架下实现OBB的检测和评估。Section 5.4的OBB回归方法是我们需要重点理解和实现的部分。**

---

**第三篇： "Real-Time High-Resolution Background Matting" (Lin et al.)**

这篇论文的主题是**背景抠图 (Background Matting)**，即在已知背景的情况下，实时、高分辨率地将前景（通常是人）从视频中精确分割出来，并提取alpha蒙版。

**阅读时应注意：**

1.  **与我们项目的直接相关性**：
    *   **较低**。这篇论文的技术核心（双网络结构、基于背景参考的alpha抠图）与我们的飞机目标检测、遮挡模拟（高斯光斑）、倾斜框回归等任务没有直接的技术重叠。
    *   我们的任务是**检测**目标，而这篇论文是**分割/抠出**已知前景。
    *   我们的"遮挡"是由高斯光斑模拟的，而这篇论文的"背景"是预先拍摄的干净背景帧。

2.  **潜在的间接启发（可能比较牵强，需谨慎判断）：**
    *   **处理高分辨率图像的策略 (Section 4)**：论文提出用一个低分辨率的基础网络处理全图，然后用一个高分辨率的精炼网络在选定的"错误区域"进行优化。这种"粗到细"或者"全局到局部"的思想在处理大图像时是通用的。如果我们在处理DOTA的大图像时遇到严重的性能瓶颈，可以思考是否能借鉴类似的策略（但Faster R-CNN本身通过FPN等结构也有多尺度处理能力）。
    *   **误差预测图 (Error Prediction Map, Ec)**：基础网络会预测一个误差图，指导精炼网络在哪里进行处理。如果我们的遮挡分析需要特别关注某些区域，也许这个概念能带来一点点灵感。

3.  **数据集 (VideoMatte240K, PhotoMatte13K/85)**：这些是抠图数据集，与我们的目标检测数据集DOTA不同。

**这篇论文对我们项目的核心价值可能非常有限。除非老师有特别说明，否则我们应将主要精力放在前两篇论文上。** 如果时间充裕，可以了解一下其处理高分辨率视频的通用思路，但不要期望从中找到直接解决飞机检测或遮挡问题的方案。

---

**总结我们阅读论文时应重点关注并结合项目思考的问题：**

1.  **如何有效地在DOTA数据集上训练一个能够检测倾斜飞机框的Faster R-CNN类模型？** (综合Paper 1的锚点调整和Paper 2的OBB回归方法)
2.  **DOTA数据集的标注（四点OBB）如何用于定义"目标中心"？** (Paper 2，Section 3.3)
3.  **如何处理DOTA的大尺寸图像进行训练和测试？** (Paper 2的裁剪策略)
4.  **遮挡模拟（高斯光斑）如何整合到训练/测试流程中？** (论文本身不涉及，需要我们自己设计，但要知道是在什么模型基础上做)
5.  **如何设计实验来分析"遮挡程度"和"目标尺度"对检测结果的影响？** (论文提供检测模型和评估方法，我们需要基于此设计变量控制实验)
6.  **哪些训练参数、数据增强方法值得借鉴？** (Paper 1)

</details>